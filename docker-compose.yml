# docker-compose.yml
# Purpose: Production deployment OPTIMIZED for 2 vCPU + 4GB RAM + 20 concurrent users
# Updated: Oct 7, 2025 - Faster updates with efficient resource allocation
# Reduces server load: Single backend, optimized workers, pgbouncer pooling, Redis caching, Nginx proxy
# Test: docker-compose up --build

services:
  # NOTE: PostgreSQL runs externally on Hetzner server (46.62.216.158:5432)
  # Using external PostgreSQL for better data security and persistence
  # Database: crypto_tracker_db
  # Managed via pgAdmin: http://46.62.216.158:5050
  # PgBouncer REMOVED - Direct connection to PostgreSQL for stability

  # Redis for Caching and Celery - Optimized for faster updates with persistence
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    command: >
      redis-server 
      --appendonly yes 
      --maxmemory 256mb 
      --maxmemory-policy allkeys-lru 
      --tcp-backlog 511
      --tcp-keepalive 60
      --timeout 0
      --save ""
      --stop-writes-on-bgsave-error no
    volumes:
      - redis_data:/data
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 10
      start_period: 10s
    restart: always

  # Backend Replica 1 (Only one for 4GB RAM)
  backend1: &backend-service
    build:
      context: ./backend
      dockerfile: Dockerfile
    env_file:
      - ./backend/.env
    depends_on:
      redis:
        condition: service_healthy
    volumes:
      - ./backend:/app
    expose:
      - "8000"
    deploy:
      resources:
        limits:
          cpus: '0.6'
          memory: 1024M
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "manage.py", "check"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Celery Worker for Background Tasks - Optimized for 20 concurrent users
  celery-worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    entrypoint: []
    command: celery -A project_config worker --loglevel=info --concurrency=2 --prefetch-multiplier=1 --max-memory-per-child=150000 --max-tasks-per-child=100
    env_file:
      - ./backend/.env
    volumes:
      - ./backend:/app
    deploy:
      resources:
        limits:
          cpus: '0.6'
          memory: 512M
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "celery -A project_config inspect ping -d celery@$$HOSTNAME || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

    # Celery Beat Scheduler - Optimized intervals for 20 concurrent users
  celery-beat:
    build:
      context: ./backend
      dockerfile: Dockerfile
    entrypoint: []
    command: celery -A project_config beat --loglevel=info --scheduler django_celery_beat.schedulers:DatabaseScheduler
    env_file:
      - ./backend/.env
    volumes:
      - ./backend:/app
    deploy:
      resources:
        limits:
          cpus: '0.2'
          memory: 256M
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "ps aux | grep 'celery.*beat' | grep -v grep || exit 1"]
      interval: 60s
      timeout: 15s
      retries: 5
      start_period: 60s

  # Binance Data Worker - Fetches real crypto data from Binance API - Optimized for WebSocket
  data-worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    user: appuser
    working_dir: /app
    entrypoint: []
    command: >
      bash -c "
        export PATH=/home/appuser/.local/bin:$$PATH &&
        export PYTHONPATH=/app &&
        echo 'â³ Waiting for external database to be ready...' &&
        echo 'ðŸ”„ Running database migrations...' &&
        python manage.py migrate --check || python manage.py migrate &&
        echo 'âœ… Migrations complete!' &&
        echo 'ðŸš€ Starting Binance WebSocket data fetcher...' &&
        python manage.py start_websocket
      "
    env_file:
      - ./backend/.env
    volumes:
      - ./backend:/app
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 448M
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "ps aux | grep 'start_websocket' | grep -v grep || exit 1"]
      interval: 60s
      timeout: 15s
      retries: 5
      start_period: 90s

  # Single Calculation Worker for metrics processing - Optimized for 80s interval
  calc-worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    entrypoint: []
    command: celery -A project_config worker --loglevel=info --concurrency=2 --hostname=calc-worker@%h --prefetch-multiplier=1 --max-memory-per-child=100000 --max-tasks-per-child=100
    env_file:
      - ./backend/.env
    volumes:
      - ./backend:/app
    deploy:
      resources:
        limits:
          cpus: '0.4'
          memory: 320M
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "celery -A project_config inspect ping -d calc-worker@$$HOSTNAME || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # NOTE: Telegram Bot Integration
  # The bot runs automatically in the celery-beat service (see below)
  # For manual testing: docker-compose exec backend1 python manage.py telegram_polling
  # For production webhook: docker-compose exec backend1 python manage.py set_telegram_webhook https://yourdomain.com/api/telegram/webhook/

  # Nginx Load Balancer (Optimized for single backend)
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"      # HTTP port for volusignal.com
      - "443:443"    # HTTPS port for SSL
      - "8080:80"    # Keep 8080 for backward compatibility
      - "8081:8081"  # Status page
    volumes:
      - ./nginx/ssl_nginx.conf:/etc/nginx/nginx.conf:ro
      - /etc/letsencrypt:/etc/letsencrypt:ro  # SSL certificates
      - /var/www/certbot:/var/www/certbot:ro  # Certbot webroot
    deploy:
      resources:
        limits:
          cpus: '0.2'
          memory: 128M
    depends_on:
      backend1:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "ps aux | grep 'nginx' | grep -v grep || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 20s

  # Frontend - PRODUCTION BUILD (Fast & Optimized) - Optimized for 20 concurrent users
  # Built locally to avoid macOS Docker SIGBUS, then copied into container
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        - NEXT_PUBLIC_API_URL=https://volusignal.com
        - NEXT_PUBLIC_WS_URL=wss://volusignal.com
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=https://volusignal.com
      - NEXT_PUBLIC_WS_URL=wss://volusignal.com
      - NODE_ENV=production
      - NEXT_TELEMETRY_DISABLED=1
    extra_hosts:
      - "host.docker.internal:host-gateway"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
    depends_on:
      - nginx
      - backend1
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "node -e \"require('http').get('http://localhost:3000', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})\""]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

volumes:
  redis_data: